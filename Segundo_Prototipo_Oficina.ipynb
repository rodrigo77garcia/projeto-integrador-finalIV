{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodrigo77garcia/projeto-integrador-finalIV/blob/master/Segundo_Prototipo_Oficina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geração de Dados Sintéticos\n",
        "\n"
      ],
      "metadata": {
        "id": "navSCv6c9Ge1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_eUAw1-pJwr",
        "outputId": "9da1df51-8cf1-42c7-ac94-b1b44f4add9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID_Servico        Data_Entrada          Data_Saida          Modelo_Bomba  \\\n",
            "0        1000 2023-04-13 11:28:00 2023-04-15 14:28:00            Bosch VP44   \n",
            "1        1001 2023-09-28 15:20:00 2023-10-01 17:20:00            Bosch VP44   \n",
            "2        1002 2023-04-13 17:18:00 2023-04-16 19:18:00         Stanadyne DB2   \n",
            "3        1003 2023-08-03 15:52:00 2023-08-06 16:52:00         Stanadyne DB2   \n",
            "4        1004 2023-04-10 15:23:00 2023-04-12 18:23:00  Common Rail (Gen. 2)   \n",
            "\n",
            "        Problema_Relatado         Etapas_Manutencao Tecnico_Responsavel  \\\n",
            "0       Perda de Potência      Diagnóstico e Ajuste           Técnico A   \n",
            "1     Vazamento de Diesel  Substituição de Válvulas           Técnico A   \n",
            "2  Marcha Lenta Irregular            Troca de Bicos           Técnico C   \n",
            "3       Perda de Potência           Reparo Completo           Técnico C   \n",
            "4        Falha na Partida  Substituição de Válvulas           Técnico D   \n",
            "\n",
            "  Status_Final     Peca_Utilizada  Custo_Pecas  Custo_Mao_Obra  \\\n",
            "0    Concluído            Nenhuma            0            1209   \n",
            "1    Concluído  Kit Reparo Basico          150             895   \n",
            "2    Concluído  Kit Reparo Basico          150            1411   \n",
            "3    Concluído  Kit Reparo Basico          150             836   \n",
            "4    Concluído  Kit Reparo Basico          150            1098   \n",
            "\n",
            "   Valor_Total_Servico Reclamacao_Posterior  Lead_Time_Dias  \n",
            "0                 1816                  Não        2.125000  \n",
            "1                 1357                  Não        3.083333  \n",
            "2                 2188                  Não        3.083333  \n",
            "3                 1186                  Sim        3.041667  \n",
            "4                 1713                  Não        2.125000  \n",
            "\n",
            "Conjunto de dados sintéticos gerado com 500 registros.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- Parâmetros de Simulação ---\n",
        "N_SERVICOS = 500\n",
        "DATA_INICIO = datetime(2023, 1, 1)\n",
        "\n",
        "# Listas de Opções\n",
        "modelos_bomba = ['Bosch VP44', 'Delphi DPCN', 'Stanadyne DB2', 'Denso HP3', 'Common Rail (Gen. 1)', 'Common Rail (Gen. 2)']\n",
        "problemas_relatados = ['Falha na Partida', 'Fumaça Excessiva', 'Perda de Potência', 'Marcha Lenta Irregular', 'Vazamento de Diesel']\n",
        "etapas_manutencao = ['Limpeza e Calibração', 'Troca de Bicos', 'Substituição de Válvulas', 'Reparo Completo', 'Diagnóstico e Ajuste']\n",
        "tecnicos = ['Técnico A', 'Técnico B', 'Técnico C', 'Técnico D']\n",
        "status_final = ['Concluído', 'Aguardando Peça', 'Retrabalho']\n",
        "pecas_custo = {\n",
        "    'Kit Reparo Basico': 150,\n",
        "    'Bico Injetor': 450,\n",
        "    'Válvula Reguladora': 600,\n",
        "    'Sensor de Pressão': 300,\n",
        "    'Nenhuma': 0\n",
        "}\n",
        "\n",
        "# --- Geração dos Dados ---\n",
        "np.random.seed(42) # Para reprodutibilidade\n",
        "\n",
        "# 1. Datas de Entrada e Saída\n",
        "data_entrada = [DATA_INICIO + timedelta(days=np.random.randint(0, 365), hours=np.random.randint(8, 18), minutes=np.random.randint(0, 60)) for _ in range(N_SERVICOS)]\n",
        "data_saida = [dt + timedelta(days=np.random.randint(1, 5), hours=np.random.randint(1, 4)) for dt in data_entrada]\n",
        "\n",
        "# 2. Outras Colunas Aleatórias\n",
        "df = pd.DataFrame({\n",
        "    'ID_Servico': range(1000, 1000 + N_SERVICOS),\n",
        "    'Data_Entrada': data_entrada,\n",
        "    'Data_Saida': data_saida,\n",
        "    'Modelo_Bomba': np.random.choice(modelos_bomba, N_SERVICOS, p=[0.2, 0.15, 0.1, 0.15, 0.2, 0.2]),\n",
        "    'Problema_Relatado': np.random.choice(problemas_relatados, N_SERVICOS),\n",
        "    'Etapas_Manutencao': np.random.choice(etapas_manutencao, N_SERVICOS),\n",
        "    'Tecnico_Responsavel': np.random.choice(tecnicos, N_SERVICOS),\n",
        "    'Status_Final': np.random.choice(status_final, N_SERVICOS, p=[0.85, 0.10, 0.05]),\n",
        "})\n",
        "\n",
        "# 3. Peças Utilizadas e Custos (com correlação)\n",
        "df['Peca_Utilizada'] = np.random.choice(list(pecas_custo.keys()), N_SERVICOS, p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
        "df['Custo_Pecas'] = df['Peca_Utilizada'].map(pecas_custo)\n",
        "df['Custo_Mao_Obra'] = np.random.randint(500, 1500, N_SERVICOS)\n",
        "df['Valor_Total_Servico'] = df['Custo_Pecas'] + df['Custo_Mao_Obra'] + np.random.randint(200, 800, N_SERVICOS) # Margem de lucro simulada\n",
        "\n",
        "# 4. Variável-Alvo ML: Reclamação Posterior (Simulando uma tendência)\n",
        "# Ex: Técnico A tem menos reclamação. Reparos completos em Bosch VP44 tem mais.\n",
        "prob_base_reclamacao = 0.08\n",
        "df['Reclamacao_Posterior'] = np.random.rand(N_SERVICOS) < prob_base_reclamacao\n",
        "\n",
        "# Ajustes de probabilidade para simular tendências\n",
        "df.loc[df['Tecnico_Responsavel'] == 'Técnico A', 'Reclamacao_Posterior'] = np.random.rand(len(df[df['Tecnico_Responsavel'] == 'Técnico A'])) < 0.03\n",
        "df.loc[(df['Modelo_Bomba'] == 'Bosch VP44') & (df['Etapas_Manutencao'] == 'Reparo Completo'), 'Reclamacao_Posterior'] = np.random.rand(len(df[(df['Modelo_Bomba'] == 'Bosch VP44') & (df['Etapas_Manutencao'] == 'Reparo Completo')])) < 0.15\n",
        "\n",
        "# Conversão para string Booleana (para visualização)\n",
        "df['Reclamacao_Posterior'] = df['Reclamacao_Posterior'].map({True: 'Sim', False: 'Não'})\n",
        "\n",
        "# 5. Cálculo do Lead Time (Tempo de Serviço)\n",
        "df['Lead_Time_Dias'] = (df['Data_Saida'] - df['Data_Entrada']).dt.total_seconds() / (24 * 3600)\n",
        "\n",
        "print(df.head())\n",
        "print(f\"\\nConjunto de dados sintéticos gerado com {len(df)} registros.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geração de Indicadores Chaves (KPI)"
      ],
      "metadata": {
        "id": "vqu3bxLc9sXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Indicadores de Gestão de Serviço e Finanças ---\n",
        "\n",
        "# 1. Transparência/Competitividade: Lead Time Médio\n",
        "lead_time_medio = df['Lead_Time_Dias'].mean()\n",
        "\n",
        "# 2. Redução de Reclamações: Taxa Global de Reclamação\n",
        "taxa_reclamacao_global = (df['Reclamacao_Posterior'] == 'Sim').sum() / N_SERVICOS\n",
        "\n",
        "# 3. Finanças: Valor Médio de Serviço\n",
        "valor_medio_servico = df['Valor_Total_Servico'].mean()\n",
        "\n",
        "# 4. Qualidade/Organização: Status do Estoque (Simulado por Aguardando Peça)\n",
        "servicos_aguardando_peca = (df['Status_Final'] == 'Aguardando Peça').sum()\n",
        "\n",
        "# 5. Desempenho do Técnico: Taxa de Reclamação por Técnico\n",
        "reclamacao_por_tecnico = df.groupby('Tecnico_Responsavel')['Reclamacao_Posterior'].apply(lambda x: (x == 'Sim').sum() / len(x)).sort_values(ascending=False)\n",
        "\n",
        "# 6. Estoque: Peças Mais Utilizadas (Demanda)\n",
        "demanda_pecas = df['Peca_Utilizada'].value_counts(normalize=True).head(3) * 100 # Top 3 em %\n",
        "\n",
        "# --- Apresentação dos Indicadores ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"             INDICADORES-CHAVE (KPIs)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"1. Tempo Médio de Serviço (Lead Time): \\t{lead_time_medio:.2f} dias\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"2. Taxa Global de Reclamação (Objetivo: < 5%): \\t{taxa_reclamacao_global:.2%}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"3. Serviços em Espera (Estoque/Gestão): \\t{servicos_aguardando_peca} serviços\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"4. Valor Médio de Serviço: \\t\\tR$ {valor_medio_servico:,.2f}\")\n",
        "print(\"-\" * 50)\n",
        "print(\"5. Taxa de Reclamação por Técnico:\")\n",
        "print(reclamacao_por_tecnico.apply(lambda x: f\"{x:.2%}\"))\n",
        "print(\"-\" * 50)\n",
        "print(\"6. Top 3 Peças Mais Utilizadas (Demanda de Estoque):\")\n",
        "print(demanda_pecas.apply(lambda x: f\"{x:.2f}%\"))\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rqTwnJjptod",
        "outputId": "2740146c-9ab9-4191-874b-396b97b8e31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "             INDICADORES-CHAVE (KPIs)\n",
            "==================================================\n",
            "1. Tempo Médio de Serviço (Lead Time): \t2.50 dias\n",
            "--------------------------------------------------\n",
            "2. Taxa Global de Reclamação (Objetivo: < 5%): \t8.00%\n",
            "--------------------------------------------------\n",
            "3. Serviços em Espera (Estoque/Gestão): \t46 serviços\n",
            "--------------------------------------------------\n",
            "4. Valor Médio de Serviço: \t\tR$ 1,828.66\n",
            "--------------------------------------------------\n",
            "5. Taxa de Reclamação por Técnico:\n",
            "Tecnico_Responsavel\n",
            "Técnico D    11.11%\n",
            "Técnico C     9.92%\n",
            "Técnico B     9.17%\n",
            "Técnico A     2.27%\n",
            "Name: Reclamacao_Posterior, dtype: object\n",
            "--------------------------------------------------\n",
            "6. Top 3 Peças Mais Utilizadas (Demanda de Estoque):\n",
            "Peca_Utilizada\n",
            "Kit Reparo Basico     31.80%\n",
            "Bico Injetor          24.00%\n",
            "Válvula Reguladora    19.80%\n",
            "Name: proportion, dtype: object\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparação para o Machine Learning"
      ],
      "metadata": {
        "id": "2Drogd79-pLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Certifique-se de que o DataFrame 'df' do passo anterior está carregado\n",
        "# Se você está executando em um novo notebook ou sessão, recarregue o código de geração de dados.\n",
        "\n",
        "# 1. Definir Features (X) e Target (y)\n",
        "features = ['Modelo_Bomba', 'Etapas_Manutencao', 'Tecnico_Responsavel', 'Peca_Utilizada', 'Lead_Time_Dias', 'Valor_Total_Servico']\n",
        "X = df[features]\n",
        "y = df['Reclamacao_Posterior'].map({'Sim': 1, 'Não': 0}) # Converter Target para 1 e 0\n",
        "\n",
        "# 2. One-Hot Encoding para variáveis categóricas\n",
        "X_encoded = pd.get_dummies(X, columns=['Modelo_Bomba', 'Etapas_Manutencao', 'Tecnico_Responsavel', 'Peca_Utilizada'], drop_first=True)\n",
        "\n",
        "# 3. Divisão Treino/Teste\n",
        "# Usaremos 70% dos dados para treinar e 30% para testar\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# 4. Normalização (Escalonamento)\n",
        "# Importante para Redes Neurais. Escala as variáveis numéricas para ter média 0 e desvio padrão 1.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Identificar colunas numéricas (aquelas que não foram transformadas pelo OHE)\n",
        "numerical_cols = ['Lead_Time_Dias', 'Valor_Total_Servico']\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "print(\"Dados prontos para o ML.\")\n",
        "print(f\"Dimensão dos dados de treino (Features): {X_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anJaFIeup2Sv",
        "outputId": "15fea058-c276-4a7a-9186-3df222427367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados prontos para o ML.\n",
            "Dimensão dos dados de treino (Features): (350, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arvore de Decisão"
      ],
      "metadata": {
        "id": "57sYhlY4-4Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Instanciar e Treinar o Modelo\n",
        "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42) # Limitamos a profundidade para evitar overfitting\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# 2. Previsão e Avaliação\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "y_proba_dt = dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"       MODELO 1: ÁRVORE DE DECISÃO\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Acurácia no Teste: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
        "print(\"\\nRelatório de Classificação (Reclamação):\")\n",
        "print(classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAPIfnBnqLZ1",
        "outputId": "0d6d08e5-4d46-40d6-b0d2-261c6b03eff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "       MODELO 1: ÁRVORE DE DECISÃO\n",
            "==================================================\n",
            "Acurácia no Teste: 0.9000\n",
            "\n",
            "Relatório de Classificação (Reclamação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95       138\n",
            "           1       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.90       150\n",
            "   macro avg       0.46      0.49      0.47       150\n",
            "weighted avg       0.84      0.90      0.87       150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapear a importância das features\n",
        "feature_importances_dt = pd.Series(dt_model.feature_importances_, index=X_train.columns)\n",
        "top_5_dt = feature_importances_dt.nlargest(5)\n",
        "\n",
        "print(\"\\nTop 5 Fatores que Mais Contribuem para Reclamações (Árvore de Decisão):\")\n",
        "print(top_5_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siNVNM2TqTDC",
        "outputId": "9bd3c65b-b2c8-4456-855d-ceb375628511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 Fatores que Mais Contribuem para Reclamações (Árvore de Decisão):\n",
            "Valor_Total_Servico                  0.568969\n",
            "Etapas_Manutencao_Reparo Completo    0.109865\n",
            "Lead_Time_Dias                       0.078944\n",
            "Peca_Utilizada_Sensor de Pressão     0.077850\n",
            "Modelo_Bomba_Common Rail (Gen. 2)    0.067704\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rede Neurais"
      ],
      "metadata": {
        "id": "brvZQrzy_ab2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# 1. Instanciar e Treinar o Modelo\n",
        "# Estrutura simples: duas camadas ocultas com 10 e 5 neurônios, respectivamente\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=500, random_state=42, solver='adam')\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# 2. Previsão e Avaliação\n",
        "y_pred_mlp = mlp_model.predict(X_test)\n",
        "y_proba_mlp = mlp_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"          MODELO 2: REDE NEURAL (MLP)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Acurácia no Teste: {accuracy_score(y_test, y_pred_mlp):.4f}\")\n",
        "print(\"\\nRelatório de Classificação (Reclamação):\")\n",
        "print(classification_report(y_test, y_pred_mlp))"
      ],
      "metadata": {
        "id": "_a7-ThtnqZGO",
        "outputId": "4839ef78-cffe-4dc2-f467-bd09d61cf1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "          MODELO 2: REDE NEURAL (MLP)\n",
            "==================================================\n",
            "Acurácia no Teste: 0.9133\n",
            "\n",
            "Relatório de Classificação (Reclamação):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95       138\n",
            "           1       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.91       150\n",
            "   macro avg       0.46      0.50      0.48       150\n",
            "weighted avg       0.85      0.91      0.88       150\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saída dos Dados para o Excel"
      ],
      "metadata": {
        "id": "hEZLx30oAh8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- 1. Geração do Conjunto de Dados Sintéticos (Repetindo o Setup) ---\n",
        "N_SERVICOS = 500\n",
        "DATA_INICIO = datetime(2023, 1, 1)\n",
        "modelos_bomba = ['Bosch VP44', 'Delphi DPCN', 'Stanadyne DB2', 'Denso HP3', 'Common Rail (Gen. 1)', 'Common Rail (Gen. 2)']\n",
        "problemas_relatados = ['Falha na Partida', 'Fumaça Excessiva', 'Perda de Potência', 'Marcha Lenta Irregular', 'Vazamento de Diesel']\n",
        "etapas_manutencao = ['Limpeza e Calibração', 'Troca de Bicos', 'Substituição de Válvulas', 'Reparo Completo', 'Diagnóstico e Ajuste']\n",
        "tecnicos = ['Técnico A', 'Técnico B', 'Técnico C', 'Técnico D']\n",
        "status_final = ['Concluído', 'Aguardando Peça', 'Retrabalho']\n",
        "pecas_custo = {'Kit Reparo Basico': 150, 'Bico Injetor': 450, 'Válvula Reguladora': 600, 'Sensor de Pressão': 300, 'Nenhuma': 0}\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "data_entrada = [DATA_INICIO + timedelta(days=np.random.randint(0, 365), hours=np.random.randint(8, 18), minutes=np.random.randint(0, 60)) for _ in range(N_SERVICOS)]\n",
        "data_saida = [dt + timedelta(days=np.random.randint(1, 5), hours=np.random.randint(1, 4)) for dt in data_entrada]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'ID_Servico': range(1000, 1000 + N_SERVICOS),\n",
        "    'Data_Entrada': data_entrada,\n",
        "    'Data_Saida': data_saida,\n",
        "    'Modelo_Bomba': np.random.choice(modelos_bomba, N_SERVICOS, p=[0.2, 0.15, 0.1, 0.15, 0.2, 0.2]),\n",
        "    'Problema_Relatado': np.random.choice(problemas_relatados, N_SERVICOS),\n",
        "    'Etapas_Manutencao': np.random.choice(etapas_manutencao, N_SERVICOS),\n",
        "    'Tecnico_Responsavel': np.random.choice(tecnicos, N_SERVICOS),\n",
        "    'Status_Final': np.random.choice(status_final, N_SERVICOS, p=[0.85, 0.10, 0.05]),\n",
        "})\n",
        "\n",
        "df['Peca_Utilizada'] = np.random.choice(list(pecas_custo.keys()), N_SERVICOS, p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
        "df['Custo_Pecas'] = df['Peca_Utilizada'].map(pecas_custo)\n",
        "df['Custo_Mao_Obra'] = np.random.randint(500, 1500, N_SERVICOS)\n",
        "df['Valor_Total_Servico'] = df['Custo_Pecas'] + df['Custo_Mao_Obra'] + np.random.randint(200, 800, N_SERVICOS)\n",
        "prob_base_reclamacao = 0.08\n",
        "df['Reclamacao_Posterior'] = np.random.rand(N_SERVICOS) < prob_base_reclamacao\n",
        "df.loc[df['Tecnico_Responsavel'] == 'Técnico A', 'Reclamacao_Posterior'] = np.random.rand(len(df[df['Tecnico_Responsavel'] == 'Técnico A'])) < 0.03\n",
        "df.loc[(df['Modelo_Bomba'] == 'Bosch VP44') & (df['Etapas_Manutencao'] == 'Reparo Completo'), 'Reclamacao_Posterior'] = np.random.rand(len(df[(df['Modelo_Bomba'] == 'Bosch VP44') & (df['Etapas_Manutencao'] == 'Reparo Completo')])) < 0.15\n",
        "df['Reclamacao_Posterior'] = df['Reclamacao_Posterior'].map({True: 'Sim', False: 'Não'})\n",
        "df['Lead_Time_Dias'] = (df['Data_Saida'] - df['Data_Entrada']).dt.total_seconds() / (24 * 3600)\n",
        "\n",
        "# Criar uma cópia limpa dos dados para a aba Excel\n",
        "df_dados_sinteticos = df.copy()\n",
        "\n",
        "# --- 2. Geração dos Indicadores (KPIs) ---\n",
        "lead_time_medio = df['Lead_Time_Dias'].mean()\n",
        "taxa_reclamacao_global = (df['Reclamacao_Posterior'] == 'Sim').sum() / N_SERVICOS\n",
        "valor_medio_servico = df['Valor_Total_Servico'].mean()\n",
        "servicos_aguardando_peca = (df['Status_Final'] == 'Aguardando Peça').sum()\n",
        "reclamacao_por_tecnico = df.groupby('Tecnico_Responsavel')['Reclamacao_Posterior'].apply(lambda x: (x == 'Sim').sum() / len(x))\n",
        "demanda_pecas = df['Peca_Utilizada'].value_counts()\n",
        "\n",
        "# Estruturar os indicadores em um DataFrame para exportação\n",
        "kpis = {\n",
        "    'KPI': [\n",
        "        'Tempo Médio de Serviço (Dias)',\n",
        "        'Taxa Global de Reclamação',\n",
        "        'Valor Médio do Serviço (R$)',\n",
        "        'Serviços Aguardando Peça (Estoque)',\n",
        "        'Reclamação - Técnico A',\n",
        "        'Reclamação - Técnico B',\n",
        "        'Reclamação - Técnico C',\n",
        "        'Reclamação - Técnico D',\n",
        "        'Peça Mais Demandada',\n",
        "        'Peça Menos Demandada'\n",
        "    ],\n",
        "    'Valor': [\n",
        "        f\"{lead_time_medio:.2f}\",\n",
        "        f\"{taxa_reclamacao_global:.2%}\",\n",
        "        f\"{valor_medio_servico:,.2f}\",\n",
        "        servicos_aguardando_peca,\n",
        "        f\"{reclamacao_por_tecnico.get('Técnico A', 0):.2%}\",\n",
        "        f\"{reclamacao_por_tecnico.get('Técnico B', 0):.2%}\",\n",
        "        f\"{reclamacao_por_tecnico.get('Técnico C', 0):.2%}\",\n",
        "        f\"{reclamacao_por_tecnico.get('Técnico D', 0):.2%}\",\n",
        "        demanda_pecas.index[0],\n",
        "        demanda_pecas.index[-1]\n",
        "    ]\n",
        "}\n",
        "df_kpis = pd.DataFrame(kpis)\n",
        "\n",
        "\n",
        "# --- 3. Pré-processamento dos Dados para ML ---\n",
        "features = ['Modelo_Bomba', 'Etapas_Manutencao', 'Tecnico_Responsavel', 'Peca_Utilizada', 'Lead_Time_Dias', 'Valor_Total_Servico']\n",
        "X = df[features]\n",
        "y = df['Reclamacao_Posterior'].map({'Sim': 1, 'Não': 0})\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=['Modelo_Bomba', 'Etapas_Manutencao', 'Tecnico_Responsavel', 'Peca_Utilizada'], drop_first=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = ['Lead_Time_Dias', 'Valor_Total_Servico']\n",
        "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "\n",
        "# --- 4. Modelo: Árvore de Decisão ---\n",
        "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Extrair as regras de decisão (Justificativa Clara)\n",
        "regras_dt = export_text(dt_model, feature_names=list(X_train.columns))\n",
        "\n",
        "# Importância das Features (para a Justificativa)\n",
        "feature_importances_dt = pd.Series(dt_model.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(5)\n",
        "\n",
        "# Estruturar para Excel\n",
        "relatorio_dt = pd.DataFrame({\n",
        "    'Metrica': ['Acurácia (Teste)', 'Precisão (Reclamação)', 'Recall (Reclamação)'],\n",
        "    'Valor': [\n",
        "        accuracy_score(y_test, y_pred_dt),\n",
        "        classification_report(y_test, y_pred_dt, output_dict=True)['1']['precision'],\n",
        "        classification_report(y_test, y_pred_dt, output_dict=True)['1']['recall']\n",
        "    ]\n",
        "})\n",
        "\n",
        "df_arvore = pd.DataFrame({\n",
        "    'Tipo': ['Regras de Decisão', 'Importância dos Fatores'],\n",
        "    'Conteudo': [regras_dt, feature_importances_dt.to_string()]\n",
        "})\n",
        "\n",
        "\n",
        "# --- 5. Modelo: Rede Neural ---\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=500, random_state=42, solver='adam')\n",
        "mlp_model.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp_model.predict(X_test)\n",
        "\n",
        "# Estruturar para Excel\n",
        "relatorio_mlp = pd.DataFrame({\n",
        "    'Metrica': ['Acurácia (Teste)', 'Precisão (Reclamação)', 'Recall (Reclamação)', 'Estrutura da Rede'],\n",
        "    'Valor': [\n",
        "        accuracy_score(y_test, y_pred_mlp),\n",
        "        classification_report(y_test, y_pred_mlp, output_dict=True)['1']['precision'],\n",
        "        classification_report(y_test, y_pred_mlp, output_dict=True)['1']['recall'],\n",
        "        \"2 Camadas Ocultas (10 e 5 neurônios)\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "\n",
        "# --- 6. Exportação para Excel (Multi-Sheet) ---\n",
        "nome_arquivo = 'relatorio_oficina_ml.xlsx'\n",
        "\n",
        "# Cria um objeto ExcelWriter\n",
        "with pd.ExcelWriter(nome_arquivo, engine='openpyxl') as writer:\n",
        "    # Aba 1: Dados Brutos Sintéticos\n",
        "    df_dados_sinteticos.to_excel(writer, sheet_name='1. Dados Sintéticos', index=False)\n",
        "\n",
        "    # Aba 2: Indicadores de Gestão (KPIs)\n",
        "    df_kpis.to_excel(writer, sheet_name='2. KPIs e Finanças', index=False)\n",
        "\n",
        "    # Aba 3: Resultados da Árvore de Decisão\n",
        "    # Adicionar o relatório de métricas\n",
        "    relatorio_dt.to_excel(writer, sheet_name='3. Arvore Decisão (Regras)', startrow=0, index=False)\n",
        "    # Adicionar regras e importância (Justificativa Clara)\n",
        "    df_arvore.to_excel(writer, sheet_name='3. Arvore Decisão (Regras)', startrow=len(relatorio_dt) + 2, index=False)\n",
        "\n",
        "    # Aba 4: Resultados da Rede Neural\n",
        "    relatorio_mlp.to_excel(writer, sheet_name='4. Rede Neural (Poder Preditivo)', index=False)\n",
        "\n",
        "print(f\"\\nSucesso! O arquivo '{nome_arquivo}' foi gerado com 4 abas, contendo dados, KPIs e resultados dos modelos de Machine Learning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QomrqLSVActb",
        "outputId": "a7e81623-b004-4718-f6a3-43b29763cee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sucesso! O arquivo 'relatorio_oficina_ml.xlsx' foi gerado com 4 abas, contendo dados, KPIs e resultados dos modelos de Machine Learning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
            "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit matplotlib plotly scikit-learn pandas numpy pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNGViQNkgIdv",
        "outputId": "65905463-c3ca-4cf0-be93-633895650115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile dashboard_oficina.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# =================================================================\n",
        "# 1. FUNÇÃO DE GERAÇÃO E TREINAMENTO DE DADOS\n",
        "# =================================================================\n",
        "\n",
        "@st.cache_resource\n",
        "def gerar_dados_e_modelos():\n",
        "    \"\"\"Gera os dados sintéticos e treina os modelos ML (Árvore e MLP).\"\"\"\n",
        "    N_SERVICOS = 500\n",
        "    DATA_INICIO = datetime(2023, 1, 1)\n",
        "\n",
        "    # Listas de Opções (omitido para brevidade)\n",
        "    modelos_bomba = ['Bosch VP44', 'Delphi DPCN', 'Stanadyne DB2', 'Denso HP3', 'Common Rail (Gen. 1)', 'Common Rail (Gen. 2)']\n",
        "    problemas_relatados = ['Falha na Partida', 'Fumaça Excessiva', 'Perda de Potência', 'Marcha Lenta Irregular', 'Vazamento de Diesel']\n",
        "    etapas_manutencao = ['Limpeza e Calibração', 'Troca de Bicos', 'Substituição de Válvulas', 'Reparo Completo', 'Diagnóstico e Ajuste']\n",
        "    tecnicos = ['Técnico A', 'Técnico B', 'Técnico C', 'Técnico D']\n",
        "    status_final = ['Concluído', 'Aguardando Peça', 'Retrabalho']\n",
        "    pecas_custo = {'Kit Reparo Basico': 150, 'Bico Injetor': 450, 'Válvula Reguladora': 600, 'Sensor de Pressão': 300, 'Nenhuma': 0}\n",
        "\n",
        "    np.random.seed(42)\n",
        "\n",
        "    data_entrada = [DATA_INICIO + timedelta(days=np.random.randint(0, 365), hours=np.random.randint(8, 18), minutes=np.random.randint(0, 60)) for _ in range(N_SERVICOS)]\n",
        "    data_saida = [dt + timedelta(days=np.random.randint(1, 5), hours=np.random.randint(1, 4)) for dt in data_entrada]\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'ID_Servico': range(1000, 1000 + N_SERVICOS),\n",
        "        'Data_Entrada': data_entrada,\n",
        "        'Data_Saida': data_saida,\n",
        "        'Modelo_Bomba': np.random.choice(modelos_bomba, N_SERVICOS, p=[0.2, 0.15, 0.1, 0.15, 0.2, 0.2]),\n",
        "        'Problema_Relatado': np.random.choice(problemas_relatados, N_SERVICOS),\n",
        "        'Etapas_Manutencao': np.random.choice(etapas_manutencao, N_SERVICOS),\n",
        "        'Tecnico_Responsavel': np.random.choice(tecnicos, N_SERVICOS),\n",
        "        'Status_Final': np.random.choice(status_final, N_SERVICOS, p=[0.85, 0.10, 0.05]),\n",
        "    })\n",
        "\n",
        "    df['Peca_Utilizada'] = np.random.choice(list(pecas_custo.keys()), N_SERVICOS, p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
        "    df['Custo_Pecas'] = df['Peca_Utilizada'].map(pecas_custo)\n",
        "    df['Custo_Mao_Obra'] = np.random.randint(500, 1500, N_SERVICOS)\n",
        "    df['Valor_Total_Servico'] = df['Custo_Pecas'] + df['Custo_Mao_Obra'] + np.random.randint(200, 800, N_SERVICOS)\n",
        "\n",
        "    # Simulação da variável-alvo (Reclamação)\n",
        "    prob_base_reclamacao = 0.08\n",
        "    df['Reclamacao_Posterior'] = np.random.rand(N_SERVICOS) < prob_base_reclamacao\n",
        "    df.loc[df['Tecnico_Responsavel'] == 'Técnico A', 'Reclamacao_Posterior'] = np.random.rand(len(df[df['Tecnico_Responsavel'] == 'Técnico A'])) < 0.03\n",
        "    df.loc[(df['Modelo_Bomba'] == 'Bosch VP44') & (df['Etapas_Manutencao'] == 'Reparo Completo'), 'Reclamacao_Posterior'] = np.random.rand(len(df[(df['Modelo_Bomba'] == 'Bosch VP44') & (df['Etapas_Manutencao'] == 'Reparo Completo')])) < 0.15\n",
        "\n",
        "    df['Reclamacao_Posterior_Binario'] = df['Reclamacao_Posterior'].map({True: 1, False: 0})\n",
        "    df['Reclamacao_Posterior'] = df['Reclamacao_Posterior'].map({True: 'Sim', False: 'Não'})\n",
        "    df['Lead_Time_Dias'] = (df['Data_Saida'] - df['Data_Entrada']).dt.total_seconds() / (24 * 3600)\n",
        "\n",
        "    # --- Treinamento dos Modelos ---\n",
        "    features = ['Modelo_Bomba', 'Etapas_Manutencao', 'Tecnico_Responsavel', 'Peca_Utilizada', 'Lead_Time_Dias', 'Valor_Total_Servico']\n",
        "    X = df[features]\n",
        "    y = df['Reclamacao_Posterior_Binario']\n",
        "    X_encoded = pd.get_dummies(X, columns=['Modelo_Bomba', 'Etapas_Manutencao', 'Tecnico_Responsavel', 'Peca_Utilizada'], drop_first=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    numerical_cols = ['Lead_Time_Dias', 'Valor_Total_Servico']\n",
        "    X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "    X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "    dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "    dt_model.fit(X_train, y_train)\n",
        "\n",
        "    mlp_model = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=500, random_state=42, solver='adam')\n",
        "    mlp_model.fit(X_train, y_train)\n",
        "\n",
        "    return df, dt_model, mlp_model, X_train, X_test, y_test\n",
        "\n",
        "# Gera os dados e modelos (apenas uma vez)\n",
        "df, dt_model, mlp_model, X_train, X_test, y_test = gerar_dados_e_modelos()\n",
        "\n",
        "# =================================================================\n",
        "# 2. DEFINIÇÃO E EXIBIÇÃO DO DASHBOARD (Streamlit)\n",
        "# =================================================================\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "st.title(\"⚙️ Dashboard de Gestão Inteligente para Oficina Diesel\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# --- Métricas Chave (KPIs) ---\n",
        "st.header(\"1. Visão Geral da Gestão e Finanças\")\n",
        "\n",
        "col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "lead_time_medio = df['Lead_Time_Dias'].mean()\n",
        "taxa_reclamacao_global = (df['Reclamacao_Posterior'] == 'Sim').sum() / len(df)\n",
        "valor_medio_servico = df['Valor_Total_Servico'].mean()\n",
        "servicos_em_espera = (df['Status_Final'] != 'Concluído').sum()\n",
        "\n",
        "col1.metric(label=\"Tempo Médio de Reparo (TMR)\", value=f\"{lead_time_medio:.2f} dias\", delta=\"Meta: 3.0 dias\")\n",
        "col2.metric(label=\"Taxa Global de Reclamação\", value=f\"{taxa_reclamacao_global:.2%}\", delta_color=\"inverse\", delta=\"Meta: 5.0%\")\n",
        "col3.metric(label=\"Valor Médio do Serviço\", value=f\"R$ {valor_medio_servico:,.2f}\", delta=\"Aumento de 2% no mês\")\n",
        "col4.metric(label=\"Serviços em Processo/Espera\", value=servicos_em_espera, delta_color=\"off\", delta=f\"{((df['Status_Final'] == 'Aguardando Peça').sum())} aguardando peças\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# --- Análise de Qualidade e Justificativa ---\n",
        "st.header(\"2. Análise de Qualidade e Redução de Reclamações\")\n",
        "\n",
        "# Gráfico 1: Desempenho dos Técnicos\n",
        "df_reclamacao_tecnico = df.groupby('Tecnico_Responsavel')['Reclamacao_Posterior_Binario'].mean().reset_index()\n",
        "df_reclamacao_tecnico['Reclamacao_Posterior_Binario'] = df_reclamacao_tecnico['Reclamacao_Posterior_Binario'] * 100\n",
        "\n",
        "fig_tecnicos = px.bar(\n",
        "    df_reclamacao_tecnico,\n",
        "    x='Tecnico_Responsavel',\n",
        "    y='Reclamacao_Posterior_Binario',\n",
        "    title='Taxa Média de Reclamação por Técnico',\n",
        "    labels={'Reclamacao_Posterior_Binario': 'Taxa de Reclamação (%)', 'Tecnico_Responsavel': 'Técnico'},\n",
        "    color='Reclamacao_Posterior_Binario',\n",
        "    color_continuous_scale=px.colors.sequential.Reds\n",
        ")\n",
        "st.plotly_chart(fig_tecnicos, use_container_width=True)\n",
        "\n",
        "col_just, col_pecas = st.columns(2)\n",
        "\n",
        "# Gráfico 2: Fatores de Reclamação (Importância da Árvore de Decisão)\n",
        "feature_importances_dt = pd.Series(dt_model.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(5)\n",
        "fig_importancia = px.bar(\n",
        "    feature_importances_dt,\n",
        "    orientation='h',\n",
        "    title='Top 5 Fatores de Risco de Reclamação (Justificativa Clara)',\n",
        "    labels={'value': 'Importância Relativa', 'index': 'Fator'},\n",
        ")\n",
        "col_just.plotly_chart(fig_importancia, use_container_width=True)\n",
        "\n",
        "# Gráfico 3: Demanda de Peças (Organização de Estoque)\n",
        "demanda_pecas = df['Peca_Utilizada'].value_counts().reset_index()\n",
        "demanda_pecas.columns = ['Peca', 'Contagem']\n",
        "fig_pecas = px.pie(\n",
        "    demanda_pecas,\n",
        "    values='Contagem',\n",
        "    names='Peca',\n",
        "    title='Distribuição da Demanda de Peças (Estoque)',\n",
        "    hole=.3\n",
        ")\n",
        "col_pecas.plotly_chart(fig_pecas, use_container_width=True)\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# --- Análise Preditiva e Modernização ---\n",
        "st.header(\"3. Previsão de Risco (Aprendizado de Máquina)\")\n",
        "st.caption(\"A Árvore de Decisão fornece regras simples (Interpretabilidade).\")\n",
        "\n",
        "col_ml, col_regras = st.columns(2)\n",
        "\n",
        "# Exibição da Acurácia dos Modelos\n",
        "acuracia_dt = accuracy_score(y_test, dt_model.predict(X_test))\n",
        "acuracia_mlp = accuracy_score(y_test, mlp_model.predict(X_test))\n",
        "\n",
        "col_ml.markdown(f\"**Acurácia dos Modelos no Teste:**\")\n",
        "col_ml.text(f\"Árvore de Decisão: {acuracia_dt:.2%} (Bom para Regras)\")\n",
        "col_ml.text(f\"Rede Neural (MLP): {acuracia_mlp:.2%} (Bom para Previsão)\")\n",
        "\n",
        "# Exibição das Regras (Justificativa Clara)\n",
        "regras_dt = export_text(dt_model, feature_names=list(X_train.columns), decimals=2, show_weights=True)\n",
        "col_regras.subheader(\"Regras de Decisão (Árvore de Decisão)\")\n",
        "col_regras.code(regras_dt, language='text')\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Desenvolvido com Dados Sintéticos, Python e Streamlit para Aprimorar a Gestão.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4fcVV69b8g8",
        "outputId": "9eb5d025-9cca-4593-8a70-06f537aaa864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dashboard_oficina.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Cole seu token aqui ↓\n",
        "ngrok.set_auth_token(\"35TBRjHm5FzAPVsnqLZ647WamAH_3pFqSJoTTe1daxtp8FBFs\")\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Porta padrão do Streamlit\n",
        "PORT = 8501\n",
        "\n",
        "# Fecha sessões antigas do ngrok\n",
        "!kill $(lsof -t -i:{PORT}) 2>/dev/null\n",
        "\n",
        "# Inicia o Streamlit em background\n",
        "process = subprocess.Popen(['streamlit', 'run', 'dashboard_oficina.py', '--server.port', str(PORT), '--server.headless', 'true'])\n",
        "\n",
        "# Aguarda o servidor iniciar\n",
        "time.sleep(5)\n",
        "\n",
        "# Cria o túnel público\n",
        "public_url = ngrok.connect(PORT)\n",
        "print(\"🔗 URL pública do dashboard:\")\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw6dZSKcfm9j",
        "outputId": "11ed8ed8-c004-4c84-b1ea-de976591e299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 URL pública do dashboard:\n",
            "NgrokTunnel: \"https://hildegarde-unexcerpted-devona.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AFKTKGKZPGJY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}